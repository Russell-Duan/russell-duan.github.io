---
layout: post
title: "Blog Post 6"
---
## Introduction
Today, I'm going to use functional API to develop models identifying fake news. First of all, we have to import all the required libraries.

```python
import numpy as np
import pandas as pd
import tensorflow as tf
import re
import string

from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow import keras

# requires update to tensorflow 2.4
# >>> conda activate PIC16B
# >>> pip install tensorflow==2.4
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.layers.experimental.preprocessing import StringLookup

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# for embedding viz
import plotly.express as px 
import plotly.io as pio

from sklearn.decomposition import PCA

from sklearn.feature_extraction import text
```

Let's read the data from the provided URL.

```python
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
df = pd.read_csv(train_url)
```

As ususl, we use the build-in function head() to inspect the data, so that we know what are the rows and the columns.

```python
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17366</td>
      <td>Merkel: Strong result for Austria's FPO 'big c...</td>
      <td>German Chancellor Angela Merkel said on Monday...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5634</td>
      <td>Trump says Pence will lead voter fraud panel</td>
      <td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17487</td>
      <td>JUST IN: SUSPECTED LEAKER and â€œClose Confidant...</td>
      <td>On December 5, 2017, Circa s Sara Carter warne...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12217</td>
      <td>Thyssenkrupp has offered help to Argentina ove...</td>
      <td>Germany s Thyssenkrupp, has offered assistance...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5535</td>
      <td>Trump say appeals court decision on travel ban...</td>
      <td>President Donald Trump on Thursday called the ...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

As we can see above, each row has an unnamed column which we are not going to use in this blog post, and we just need to focus on the remaining three columns which are `title`, `text`, and `fake`. The `title` and `text` are what they are, and the `fake` indicates whether this news is a fake news regrarding the composter of this new where `1` means fake news and vice versa. We are going to implement a `make_dataset` function to clean up the data and transform the DataFrame into a Dataset.


```python
def make_dataset(df):
    '''
    this function clean up the data and transform it into a tf.data.Dataset

    Input
    -----
    df: pd.Dataframe, the data of news

    Output
    -----
    data: tf.data.Dataset, the dataset with two inputs and one output
    '''
    stop = text.ENGLISH_STOP_WORDS
    df["title"].apply(lambda words: ''.join(word.lower() for word in words.split() if word not in stop))
    df["text"].apply(lambda words: ''.join(word.lower() for word in words.split() if word not in stop))

    data = tf.data.Dataset.from_tensor_slices(
        (
          {
              "title" : df[["title"]], 
              "text" : df["text"]
          }, 
          {
              "fake" : df[["fake"]]
          }
         )
        )
    data.batch(100)
    return data
```

We are going to split the dataset into two parts where 80% of the data is used to train the model and 20% of the data is used for validation.

```python
data = make_dataset(df)

train_size = int(0.8*len(data))
val_size   = int(0.2*len(data))

train = data.take(train_size).batch(20)
val   = data.skip(train_size).take(val_size).batch(20)

len(train), len(val)
```




    (898, 225)

## Base Rate

```python
labels_iterator= train.unbatch().map(lambda title, fake: fake).as_numpy_iterator()
fake_news = 0
good_news = 0
for i in labels_iterator:
    if i['fake'] == [0]:
        good_news += 1
    else:
        fake_news +=1
print("Number of good news: "+str(good_news)+", number of fake news: "+str(fake_news))
```

    Number of good news: 8586, number of fake news: 9373

The base rate of the model is 9373/(8586+9373) = 52.2% which means the baseline model should have 52.2% accuracy theoretically. Now we are entering the modeling phase.

## Create Models

Before we even create the models, we have to do something called `standardization` which refers to the act of taking a some text that's "messy" in some way and making it less messy. Common standardizations include: Removing capitals; Removing punctuation; Removing HTML elements or other non-semantic content. We are only removing the punctionations and converting all letters to lowercase. In the next three models, we will use data from `title`, `text`, both `title` and `text` respectively to see which model performs the best and what data sources we need.

```python
size_vocabulary = 2000

def standardization(input_data):
    lowercase = tf.strings.lower(input_data)
    no_punctuation = tf.strings.regex_replace(lowercase,
                                  '[%s]' % re.escape(string.punctuation),'')
    return no_punctuation 


```

### Model1(Only Title)

In our first model, we are only using the `title` data to determine whether a news is fake. We pass the standardization to the vectorize layer.

```python
vectorize_layer_1 = TextVectorization(
    standardize=standardization,
    max_tokens=size_vocabulary, # only consider this many words
    output_mode='int',
    output_sequence_length=500)
vectorize_layer_1.adapt(train.map(lambda x, y: x["title"]))
```
We set the input which only contains `title`.

```python
# inputs

title_input = keras.Input(
    shape = (1,), 
    name = "title",
    dtype = "string"
)
```
Now, we are constructing a model with some layers/

```python
title_features = vectorize_layer_1(title_input)
title_features = layers.Embedding(size_vocabulary, 5, name = "embedding_title")(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.GlobalAveragePooling1D()(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.Dense(32, activation='relu')(title_features)
title_output = layers.Dense(2, name = "fake")(title_features)
```


```python
model1 = keras.Model(
    inputs = [title_input],
    outputs = title_output
)
```


```python
model1.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```
Train the model.

```python
history = model1.fit(train, 
                    validation_data=val,
                    epochs = 20, 
                    verbose = True)
```

    Epoch 1/20


    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning:
    
    Input dict contained keys ['text'] which did not match any model input. They will be ignored by the model.
    


    898/898 [==============================] - 8s 8ms/step - loss: 0.6173 - accuracy: 0.6503 - val_loss: 0.3523 - val_accuracy: 0.8846
    Epoch 2/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.2371 - accuracy: 0.9140 - val_loss: 0.1725 - val_accuracy: 0.9329
    Epoch 3/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.1630 - accuracy: 0.9391 - val_loss: 0.1414 - val_accuracy: 0.9461
    Epoch 4/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.1420 - accuracy: 0.9473 - val_loss: 0.1323 - val_accuracy: 0.9505
    Epoch 5/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.1274 - accuracy: 0.9520 - val_loss: 0.1373 - val_accuracy: 0.9472
    Epoch 6/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.1180 - accuracy: 0.9565 - val_loss: 0.1190 - val_accuracy: 0.9550
    Epoch 7/20
    898/898 [==============================] - 8s 8ms/step - loss: 0.1098 - accuracy: 0.9598 - val_loss: 0.1264 - val_accuracy: 0.9497
    Epoch 8/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.1067 - accuracy: 0.9606 - val_loss: 0.1081 - val_accuracy: 0.9581
    Epoch 9/20
    898/898 [==============================] - 8s 8ms/step - loss: 0.1013 - accuracy: 0.9625 - val_loss: 0.1132 - val_accuracy: 0.9575
    Epoch 10/20
    898/898 [==============================] - 8s 8ms/step - loss: 0.0980 - accuracy: 0.9636 - val_loss: 0.1190 - val_accuracy: 0.9514
    Epoch 11/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0955 - accuracy: 0.9651 - val_loss: 0.1414 - val_accuracy: 0.9414
    Epoch 12/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0926 - accuracy: 0.9658 - val_loss: 0.1369 - val_accuracy: 0.9434
    Epoch 13/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0886 - accuracy: 0.9663 - val_loss: 0.1410 - val_accuracy: 0.9412
    Epoch 14/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0877 - accuracy: 0.9682 - val_loss: 0.1176 - val_accuracy: 0.9557
    Epoch 15/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0872 - accuracy: 0.9676 - val_loss: 0.1334 - val_accuracy: 0.9461
    Epoch 16/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0816 - accuracy: 0.9709 - val_loss: 0.1198 - val_accuracy: 0.9537
    Epoch 17/20
    898/898 [==============================] - 8s 8ms/step - loss: 0.0803 - accuracy: 0.9709 - val_loss: 0.1245 - val_accuracy: 0.9530
    Epoch 18/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0817 - accuracy: 0.9706 - val_loss: 0.1590 - val_accuracy: 0.9343
    Epoch 19/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0803 - accuracy: 0.9713 - val_loss: 0.1220 - val_accuracy: 0.9539
    Epoch 20/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0773 - accuracy: 0.9722 - val_loss: 0.1429 - val_accuracy: 0.9434



```python
from matplotlib import pyplot as plt
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fe4e6b6d9d0>




![png](/images/output_14_1.png)

Our first model has an stablized accuracy at 95%-97%, and our validation accuracy has an final accuracy at 94%-95%.


### Model2(Only Text)

We repeat the same step as we construct our first model, but we only use `text` this time.

```python
vectorize_layer_2 = TextVectorization(
    standardize=standardization,
    max_tokens=size_vocabulary, # only consider this many words
    output_mode='int',
    output_sequence_length=500)
vectorize_layer_2.adapt(train.map(lambda x, y: x["text"]))
```


```python
# inputs

text_input = keras.Input(
    shape = (1,), 
    name = "text",
    dtype = "string"
)
```


```python
text_features = vectorize_layer_1(text_input)
text_features = layers.Embedding(size_vocabulary, 5, name = "embedding_text")(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.GlobalAveragePooling1D()(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.Dense(32, activation='relu')(text_features)
text_output = layers.Dense(2, name = "fake")(text_features)
```


```python
model2 = keras.Model(
    inputs = [text_input],
    outputs = text_output
)
```


```python
model2.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```


```python
history = model2.fit(train, 
                    validation_data=val,
                    epochs = 20, 
                    verbose = True)
```

    Epoch 1/20


    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning:
    
    Input dict contained keys ['title'] which did not match any model input. They will be ignored by the model.
    


    898/898 [==============================] - 7s 7ms/step - loss: 0.3785 - accuracy: 0.8538 - val_loss: 0.1586 - val_accuracy: 0.9557
    Epoch 2/20
    898/898 [==============================] - 7s 7ms/step - loss: 0.1419 - accuracy: 0.9613 - val_loss: 0.1134 - val_accuracy: 0.9677
    Epoch 3/20
    898/898 [==============================] - 6s 7ms/step - loss: 0.1120 - accuracy: 0.9683 - val_loss: 0.1004 - val_accuracy: 0.9701
    Epoch 4/20
    898/898 [==============================] - 7s 7ms/step - loss: 0.0959 - accuracy: 0.9733 - val_loss: 0.0955 - val_accuracy: 0.9699
    Epoch 5/20
    898/898 [==============================] - 6s 7ms/step - loss: 0.0845 - accuracy: 0.9774 - val_loss: 0.0876 - val_accuracy: 0.9737
    Epoch 6/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0768 - accuracy: 0.9786 - val_loss: 0.0903 - val_accuracy: 0.9699
    Epoch 7/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0690 - accuracy: 0.9807 - val_loss: 0.0885 - val_accuracy: 0.9708
    Epoch 8/20
    898/898 [==============================] - 6s 7ms/step - loss: 0.0637 - accuracy: 0.9819 - val_loss: 0.0850 - val_accuracy: 0.9739
    Epoch 9/20
    898/898 [==============================] - 7s 7ms/step - loss: 0.0578 - accuracy: 0.9846 - val_loss: 0.0842 - val_accuracy: 0.9755
    Epoch 10/20
    898/898 [==============================] - 6s 7ms/step - loss: 0.0531 - accuracy: 0.9852 - val_loss: 0.0926 - val_accuracy: 0.9726
    Epoch 11/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0510 - accuracy: 0.9855 - val_loss: 0.0982 - val_accuracy: 0.9708
    Epoch 12/20
    898/898 [==============================] - 7s 7ms/step - loss: 0.0479 - accuracy: 0.9866 - val_loss: 0.0882 - val_accuracy: 0.9748
    Epoch 13/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0450 - accuracy: 0.9870 - val_loss: 0.0946 - val_accuracy: 0.9735
    Epoch 14/20
    898/898 [==============================] - 7s 7ms/step - loss: 0.0411 - accuracy: 0.9886 - val_loss: 0.0974 - val_accuracy: 0.9744
    Epoch 15/20
    898/898 [==============================] - 6s 7ms/step - loss: 0.0399 - accuracy: 0.9887 - val_loss: 0.1006 - val_accuracy: 0.9739
    Epoch 16/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0390 - accuracy: 0.9888 - val_loss: 0.0993 - val_accuracy: 0.9746
    Epoch 17/20
    898/898 [==============================] - 7s 7ms/step - loss: 0.0395 - accuracy: 0.9886 - val_loss: 0.1092 - val_accuracy: 0.9722
    Epoch 18/20
    898/898 [==============================] - 7s 7ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.1099 - val_accuracy: 0.9726
    Epoch 19/20
    898/898 [==============================] - 6s 7ms/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.1109 - val_accuracy: 0.9742
    Epoch 20/20
    898/898 [==============================] - 6s 7ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 0.1155 - val_accuracy: 0.9710



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fe4e673ed90>




![png](/images/output_22_1_1.png)

Our second model has an stablized accuracy at 97%-99%, and our validation accuracy has an final accuracy at 96%-97%. The second model performed better than the first model, and the overfitting didn't occur since the validation accuracy is almost the same with the training accuracy.


### Model3(Both)

In our last model, we need to combine the two set of layers in the first two model, while using both `title` and `text` in training.

```python
both_features = layers.concatenate([text_features, title_features], axis = 1)
both_output = layers.Dense(2, name = "fake")(both_features)
```


```python
model3= keras.Model(
    inputs = [title_input, text_input],
    outputs = both_output
)
```


```python
model3.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```


```python
history = model3.fit(train, 
                    validation_data=val,
                    epochs = 20, 
                    verbose = True)
```

    Epoch 1/20
    898/898 [==============================] - 9s 9ms/step - loss: 0.3798 - accuracy: 0.8487 - val_loss: 0.1560 - val_accuracy: 0.9572
    Epoch 2/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.1371 - accuracy: 0.9623 - val_loss: 0.1118 - val_accuracy: 0.9659
    Epoch 3/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0955 - accuracy: 0.9746 - val_loss: 0.0873 - val_accuracy: 0.9719
    Epoch 4/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0667 - accuracy: 0.9817 - val_loss: 0.0672 - val_accuracy: 0.9764
    Epoch 5/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0508 - accuracy: 0.9855 - val_loss: 0.0534 - val_accuracy: 0.9806
    Epoch 6/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0400 - accuracy: 0.9886 - val_loss: 0.0434 - val_accuracy: 0.9842
    Epoch 7/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0323 - accuracy: 0.9909 - val_loss: 0.0420 - val_accuracy: 0.9849
    Epoch 8/20
    898/898 [==============================] - 8s 8ms/step - loss: 0.0283 - accuracy: 0.9918 - val_loss: 0.0361 - val_accuracy: 0.9869
    Epoch 9/20
    898/898 [==============================] - 8s 8ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0471 - val_accuracy: 0.9837
    Epoch 10/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.0382 - val_accuracy: 0.9864
    Epoch 11/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0394 - val_accuracy: 0.9862
    Epoch 12/20
    898/898 [==============================] - 7s 8ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0329 - val_accuracy: 0.9882
    Epoch 13/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0347 - val_accuracy: 0.9880
    Epoch 14/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0340 - val_accuracy: 0.9880
    Epoch 15/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.0401 - val_accuracy: 0.9877
    Epoch 16/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0372 - val_accuracy: 0.9880
    Epoch 17/20
    898/898 [==============================] - 8s 8ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0376 - val_accuracy: 0.9886
    Epoch 18/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0381 - val_accuracy: 0.9864
    Epoch 19/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0359 - val_accuracy: 0.9877
    Epoch 20/20
    898/898 [==============================] - 8s 9ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0395 - val_accuracy: 0.9873



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fe4d3097d90>




![png](/images/output_28_1_1.png)

Our last model has an stablized accuracy at 98%-99%, and our validation accuracy has an final accuracy at 98%-99%. The third model performed slightly better than the second model, so that we choose the third model as our final model.

In conclusion, the algorithms should use both the title and the text to determine the fake news.

## Model Evaluation


```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
test = pd.read_csv(test_url)
```


```python
df_test = make_dataset(test)
```


```python
model3.evaluate(df_test)
```

    225/225 [==============================] - 3s 12ms/step - loss: 0.0722 - accuracy: 0.9792





    [0.07223927229642868, 0.9792418479919434]

When testing the model on an unseen dataset, our last model performed super well which effectively predicts 97.92% right which meets our expectation.

## Embedding Visualization


```python
weights = model3.get_layer('embedding_text').get_weights()[0] # get the weights from the embedding layer
vocab = vectorize_layer_2.get_vocabulary()                # get the vocabulary from our data prep for later
```


```python
pca = PCA(n_components=2)
weights = pca.fit_transform(weights)
```


```python
embedding_df = pd.DataFrame({
    'word' : vocab, 
    'x0'   : weights[:,0],
    'x1'   : weights[:,1]
})
```


```python
import plotly.express as px 
fig = px.scatter(embedding_df, 
                 color_discrete_sequence=['black'],
                 x = "x0", 
                 y = "x1", 
                 size = list(np.ones(len(embedding_df))),
                 size_max = 5,
                 hover_name = "word")

fig.show()
```
{% include /images/word.html %}

The words on the far right are relevent, such as `work` and `manager`, `response` and `yes` which are interpretable. On the left side, we could also see words like `democrats` and `appeals` which sounds like political news.