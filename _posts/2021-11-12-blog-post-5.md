---
layout: post
title: Blog Post: Image Classification and Transfer Learning

---
## Load Packages and Obtain Data


```python
import os
from tensorflow.keras import utils 
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras import utils,layers,models
```


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
    68608000/68606236 [==============================] - 0s 0us/step
    68616192/68606236 [==============================] - 0s 0us/step
    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.



```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```


```python
def two_row_visualization():
    fig, ax = plt.subplots(2, 3, figsize=(10, 10))
    for images, labels in train_dataset.take(1):
        cats = np.where([labels == 0])
        dogs = np.where([labels == 1])
        for i in range(3):
            ax[0, i].imshow(images[cats[1][i]].numpy().astype("uint8"))
        for i in range(3):
            ax[1, i].imshow(images[dogs[1][i]].numpy().astype("uint8"))
```


```python
two_row_visualization()
```


![png](output_5_0.png)



```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
cat_freq = 0
dog_freq = 0
for i in labels_iterator:
    if i == 0:
        cat_freq += 1
    else:
        dog_freq+=1
print("Number of cats: "+str(cat_freq)+", number of dogs: "+str(dog_freq))
```

    Number of cats: 1000, number of dogs: 1000


## First Model


```python
model1 = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(64,activation = 'relu'),
    layers.Dense(2),
])
```


```python
model1.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset
)
```

    Epoch 1/20
    63/63 [==============================] - 3s 33ms/step - loss: 6.5181 - accuracy: 0.5580 - val_loss: 0.6842 - val_accuracy: 0.5730
    Epoch 2/20
    63/63 [==============================] - 2s 31ms/step - loss: 0.6020 - accuracy: 0.6675 - val_loss: 0.6749 - val_accuracy: 0.6040
    Epoch 3/20
    63/63 [==============================] - 2s 32ms/step - loss: 0.4923 - accuracy: 0.7590 - val_loss: 0.7557 - val_accuracy: 0.6176
    Epoch 4/20
    63/63 [==============================] - 2s 31ms/step - loss: 0.4096 - accuracy: 0.8065 - val_loss: 0.8965 - val_accuracy: 0.5953
    Epoch 5/20
    63/63 [==============================] - 2s 33ms/step - loss: 0.3653 - accuracy: 0.8355 - val_loss: 0.9456 - val_accuracy: 0.6238
    Epoch 6/20
    63/63 [==============================] - 2s 34ms/step - loss: 0.2947 - accuracy: 0.8725 - val_loss: 0.9515 - val_accuracy: 0.6337
    Epoch 7/20
    63/63 [==============================] - 2s 34ms/step - loss: 0.2868 - accuracy: 0.8780 - val_loss: 1.0169 - val_accuracy: 0.6015
    Epoch 8/20
    63/63 [==============================] - 2s 32ms/step - loss: 0.2430 - accuracy: 0.9000 - val_loss: 1.0128 - val_accuracy: 0.6176
    Epoch 9/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.2116 - accuracy: 0.9120 - val_loss: 1.3110 - val_accuracy: 0.6015
    Epoch 10/20
    63/63 [==============================] - 2s 34ms/step - loss: 0.2065 - accuracy: 0.9110 - val_loss: 1.1307 - val_accuracy: 0.6522
    Epoch 11/20
    63/63 [==============================] - 2s 33ms/step - loss: 0.1935 - accuracy: 0.9230 - val_loss: 1.3250 - val_accuracy: 0.6213
    Epoch 12/20
    63/63 [==============================] - 2s 33ms/step - loss: 0.1784 - accuracy: 0.9385 - val_loss: 1.3386 - val_accuracy: 0.6238
    Epoch 13/20
    63/63 [==============================] - 2s 31ms/step - loss: 0.1537 - accuracy: 0.9415 - val_loss: 1.4623 - val_accuracy: 0.6262
    Epoch 14/20
    63/63 [==============================] - 2s 33ms/step - loss: 0.1513 - accuracy: 0.9445 - val_loss: 1.3929 - val_accuracy: 0.6225
    Epoch 15/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.1558 - accuracy: 0.9425 - val_loss: 1.5812 - val_accuracy: 0.6163
    Epoch 16/20
    63/63 [==============================] - 2s 32ms/step - loss: 0.1613 - accuracy: 0.9410 - val_loss: 1.3714 - val_accuracy: 0.6238
    Epoch 17/20
    63/63 [==============================] - 2s 32ms/step - loss: 0.1395 - accuracy: 0.9500 - val_loss: 1.5276 - val_accuracy: 0.6473
    Epoch 18/20
    63/63 [==============================] - 2s 32ms/step - loss: 0.1124 - accuracy: 0.9625 - val_loss: 1.4916 - val_accuracy: 0.6300
    Epoch 19/20
    63/63 [==============================] - 2s 32ms/step - loss: 0.1153 - accuracy: 0.9585 - val_loss: 1.6682 - val_accuracy: 0.6300
    Epoch 20/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.1005 - accuracy: 0.9620 - val_loss: 1.4573 - val_accuracy: 0.6386



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f273f927cd0>




![png](/images/output_10_1.png)


**The accuracy of my model stabilized between 90% and 95% during training, but the accuracy stabilized between 58% and 63% during validation. Compared to the baseline, my model is 8% to 13% better. As the training accuracy is significantly higher than the validation accuracy, model1 is overfitting.**

## Model with Data Augmentation

### Random Flip


```python
random_flip = tf.keras.Sequential(
    [layers.RandomFlip("horizontal")]
)
for images, labels in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    first_image = images[0]
    for i in range(2):
        ax = plt.subplot(1, 2, i + 1)
        augmented_image = random_flip(
            tf.expand_dims(first_image, 0), training=True
        )
        plt.imshow(augmented_image[0].numpy().astype("uint8"))
```


![png](output_14_0.png)


You may find this [link](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip) useful to set parameters of RandomFlip. By setting the parameter as "horizontal", the image is a left-right flip.

### RandomRotation


```python
random_rotation = tf.keras.Sequential(
    [layers.RandomRotation((-0.2, 0.3))]
)
for images, labels in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    first_image = images[0]
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        augmented_image = random_rotation(
            tf.expand_dims(first_image, 0), training=True
        )
        plt.imshow(augmented_image[0].numpy().astype("uint8"))
```


![png](/images/output_17_0.png)


Compared to RandomFlip, RandomRotation takes in more parameters. You can find the meaning of those parameters [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation). Now, the image with rotate a random degree in between range `[-20% * 2pi, 30% * 2pi]`.


```python
model2 = models.Sequential([
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.3),
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(64,activation = 'relu'),
    layers.Dense(2),
])
```

We added the two layes `RandomFlip` and `RandomRotation` to model1, and we define the new model as model2.


```python
model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 3s 32ms/step - loss: 15.7223 - accuracy: 0.5175 - val_loss: 0.6945 - val_accuracy: 0.5371
    Epoch 2/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6999 - accuracy: 0.5235 - val_loss: 0.6808 - val_accuracy: 0.5693
    Epoch 3/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6930 - accuracy: 0.5465 - val_loss: 0.6902 - val_accuracy: 0.5396
    Epoch 4/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6868 - accuracy: 0.5630 - val_loss: 0.6816 - val_accuracy: 0.5903
    Epoch 5/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6877 - accuracy: 0.5470 - val_loss: 0.6793 - val_accuracy: 0.5631
    Epoch 6/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6839 - accuracy: 0.5640 - val_loss: 0.6811 - val_accuracy: 0.5767
    Epoch 7/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6869 - accuracy: 0.5500 - val_loss: 0.6765 - val_accuracy: 0.5965
    Epoch 8/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6812 - accuracy: 0.5535 - val_loss: 0.6775 - val_accuracy: 0.5804
    Epoch 9/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6787 - accuracy: 0.5735 - val_loss: 0.6720 - val_accuracy: 0.6027
    Epoch 10/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6720 - accuracy: 0.5885 - val_loss: 0.6769 - val_accuracy: 0.5767
    Epoch 11/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6769 - accuracy: 0.6020 - val_loss: 0.6711 - val_accuracy: 0.5817
    Epoch 12/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6732 - accuracy: 0.5845 - val_loss: 0.6758 - val_accuracy: 0.6163
    Epoch 13/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6803 - accuracy: 0.5845 - val_loss: 0.6772 - val_accuracy: 0.6238
    Epoch 14/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6784 - accuracy: 0.5955 - val_loss: 0.6728 - val_accuracy: 0.6151
    Epoch 15/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6735 - accuracy: 0.5795 - val_loss: 0.6803 - val_accuracy: 0.6126
    Epoch 16/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6713 - accuracy: 0.5955 - val_loss: 0.6716 - val_accuracy: 0.6312
    Epoch 17/20
    63/63 [==============================] - 2s 31ms/step - loss: 0.6608 - accuracy: 0.6310 - val_loss: 0.6770 - val_accuracy: 0.6015
    Epoch 18/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6625 - accuracy: 0.6055 - val_loss: 0.6807 - val_accuracy: 0.5903
    Epoch 19/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6715 - accuracy: 0.6025 - val_loss: 0.6592 - val_accuracy: 0.6163
    Epoch 20/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.6606 - accuracy: 0.6005 - val_loss: 0.6796 - val_accuracy: 0.5656



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f2741e05290>




![png](/images/output_22_1.png)


**The validation accuracy of this model ranges from 54% to 62%. The validation accuracy is less stable than model1, and its accuracy is similar compared to model1. The overall accuracy performance of model2 is worse than model1. However, there is no overfitting in model2 since the training accuracy is almost the same as the validation accuracy.**

## Data Preprocessing


```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```


```python
model3 = models.Sequential([
    preprocessor,
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.3),
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(32,activation = 'relu'),
    layers.Dense(2),
])
```


```python
model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 3s 31ms/step - loss: 0.4928 - accuracy: 0.7620 - val_loss: 0.5293 - val_accuracy: 0.7413
    Epoch 2/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4764 - accuracy: 0.7675 - val_loss: 0.5409 - val_accuracy: 0.7265
    Epoch 3/20
    63/63 [==============================] - 2s 29ms/step - loss: 0.4930 - accuracy: 0.7640 - val_loss: 0.5018 - val_accuracy: 0.7488
    Epoch 4/20
    63/63 [==============================] - 2s 29ms/step - loss: 0.4670 - accuracy: 0.7745 - val_loss: 0.5179 - val_accuracy: 0.7488
    Epoch 5/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4649 - accuracy: 0.7740 - val_loss: 0.4914 - val_accuracy: 0.7673
    Epoch 6/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4741 - accuracy: 0.7645 - val_loss: 0.5043 - val_accuracy: 0.7525
    Epoch 7/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4505 - accuracy: 0.7930 - val_loss: 0.5109 - val_accuracy: 0.7611
    Epoch 8/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4665 - accuracy: 0.7665 - val_loss: 0.5232 - val_accuracy: 0.7351
    Epoch 9/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4677 - accuracy: 0.7695 - val_loss: 0.5108 - val_accuracy: 0.7574
    Epoch 10/20
    63/63 [==============================] - 2s 29ms/step - loss: 0.4501 - accuracy: 0.7795 - val_loss: 0.5127 - val_accuracy: 0.7661
    Epoch 11/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4454 - accuracy: 0.7975 - val_loss: 0.5271 - val_accuracy: 0.7624
    Epoch 12/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4424 - accuracy: 0.7915 - val_loss: 0.4976 - val_accuracy: 0.7611
    Epoch 13/20
    63/63 [==============================] - 2s 29ms/step - loss: 0.4356 - accuracy: 0.7980 - val_loss: 0.5070 - val_accuracy: 0.7673
    Epoch 14/20
    63/63 [==============================] - 2s 29ms/step - loss: 0.4346 - accuracy: 0.8045 - val_loss: 0.5650 - val_accuracy: 0.7389
    Epoch 15/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4259 - accuracy: 0.8115 - val_loss: 0.5351 - val_accuracy: 0.7463
    Epoch 16/20
    63/63 [==============================] - 2s 29ms/step - loss: 0.4167 - accuracy: 0.8055 - val_loss: 0.5270 - val_accuracy: 0.7599
    Epoch 17/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4188 - accuracy: 0.8085 - val_loss: 0.5811 - val_accuracy: 0.7587
    Epoch 18/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4292 - accuracy: 0.8000 - val_loss: 0.5875 - val_accuracy: 0.7191
    Epoch 19/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4315 - accuracy: 0.8005 - val_loss: 0.5201 - val_accuracy: 0.7574
    Epoch 20/20
    63/63 [==============================] - 2s 30ms/step - loss: 0.4281 - accuracy: 0.7955 - val_loss: 0.5313 - val_accuracy: 0.7550



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f2741eab190>




![png](/images/output_28_1.png)



```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```


```python
model4 = models.Sequential([
    preprocessor,
    layers.RandomFlip('horizontal_and_vertical'),
    layers.RandomRotation(0.3),
    base_model_layer,
    layers.GlobalMaxPool2D(),
    layers.Dense(2)
])
```


```python
model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 48ms/step - loss: 0.7417 - accuracy: 0.8005 - val_loss: 0.1607 - val_accuracy: 0.9567
    Epoch 2/20
    63/63 [==============================] - 2s 37ms/step - loss: 0.3858 - accuracy: 0.8790 - val_loss: 0.1094 - val_accuracy: 0.9653
    Epoch 3/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.3644 - accuracy: 0.8855 - val_loss: 0.1543 - val_accuracy: 0.9641
    Epoch 4/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.4372 - accuracy: 0.8770 - val_loss: 0.1185 - val_accuracy: 0.9592
    Epoch 5/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.3071 - accuracy: 0.9005 - val_loss: 0.1483 - val_accuracy: 0.9567
    Epoch 6/20
    63/63 [==============================] - 2s 35ms/step - loss: 0.3169 - accuracy: 0.9005 - val_loss: 0.1213 - val_accuracy: 0.9629
    Epoch 7/20
    63/63 [==============================] - 2s 35ms/step - loss: 0.2857 - accuracy: 0.9025 - val_loss: 0.1213 - val_accuracy: 0.9653
    Epoch 8/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.3072 - accuracy: 0.9035 - val_loss: 0.1318 - val_accuracy: 0.9616
    Epoch 9/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.2477 - accuracy: 0.9175 - val_loss: 0.0968 - val_accuracy: 0.9691
    Epoch 10/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.2356 - accuracy: 0.9195 - val_loss: 0.0998 - val_accuracy: 0.9666
    Epoch 11/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.1925 - accuracy: 0.9245 - val_loss: 0.0971 - val_accuracy: 0.9641
    Epoch 12/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.2326 - accuracy: 0.9195 - val_loss: 0.0966 - val_accuracy: 0.9666
    Epoch 13/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.2057 - accuracy: 0.9265 - val_loss: 0.0960 - val_accuracy: 0.9666
    Epoch 14/20
    63/63 [==============================] - 2s 37ms/step - loss: 0.2369 - accuracy: 0.9165 - val_loss: 0.1011 - val_accuracy: 0.9653
    Epoch 15/20
    63/63 [==============================] - 2s 36ms/step - loss: 0.2355 - accuracy: 0.9175 - val_loss: 0.1154 - val_accuracy: 0.9653
    Epoch 16/20
    63/63 [==============================] - 2s 35ms/step - loss: 0.2124 - accuracy: 0.9235 - val_loss: 0.0993 - val_accuracy: 0.9691
    Epoch 17/20
    63/63 [==============================] - 2s 35ms/step - loss: 0.1927 - accuracy: 0.9345 - val_loss: 0.1050 - val_accuracy: 0.9616
    Epoch 18/20
    63/63 [==============================] - 2s 37ms/step - loss: 0.2227 - accuracy: 0.9225 - val_loss: 0.1653 - val_accuracy: 0.9579
    Epoch 19/20
    63/63 [==============================] - 2s 37ms/step - loss: 0.2283 - accuracy: 0.9215 - val_loss: 0.1147 - val_accuracy: 0.9629
    Epoch 20/20
    63/63 [==============================] - 2s 35ms/step - loss: 0.1920 - accuracy: 0.9340 - val_loss: 0.0954 - val_accuracy: 0.9653



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f27400d1250>




![png](/images/output_32_2.png)


### Score on Test Data


```python
model4.evaluate(test_dataset,verbose=2)
```

    6/6 - 0s - loss: 0.1156 - accuracy: 0.9688 - 259ms/epoch - 43ms/step





    [0.11558455228805542, 0.96875]




```python

```
